{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a5bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from google.cloud import storage\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "SEED = 645\n",
    "bucket_name = \"my-bigdata-project-mp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6aeef8",
   "metadata": {},
   "source": [
    "# Get data with features vector and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461bb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for data used for model\n",
    "data_path = \"gs://my-bigdata-project-mp/trusted\"\n",
    "\n",
    "# Load data into a PySpark DataFrame\n",
    "sdf = spark.read.parquet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking schema\n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8870f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the linear regression model\n",
    "model_path = \"gs://my-bigdata-project-mp/models/flight_prices_linear_regression_model\"\n",
    "\n",
    "# Load PipelineModel into a variable\n",
    "pipeline = PipelineModel.load(model_path)\n",
    "\n",
    "# Extract the model\n",
    "lr_model = pipeline.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION\n",
    "# ARG1 - matplot variable you used for your plot\n",
    "# ARG1 - Name you want to give the image.\n",
    "# ARG2 - The type you want the image to be. This function assumes we want a PNG.\n",
    "\n",
    "def save_fig(plt, img_name, img_type=\"png\"):\n",
    "    print(\"Saving figure...\")\n",
    "    # Create a memory buffer to hold the figure\n",
    "    img_data = io.BytesIO()\n",
    "    # Write the figure to the buffer\n",
    "    plt.savefig(img_data, format=img_type, bbox_inches='tight')\n",
    "    # Rewind the pointer to the start of the data\n",
    "    img_data.seek(0)\n",
    "    # Connect to Google Cloud Storage\n",
    "    storage_client = storage.Client()\n",
    "    # Point to the bucket\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    # Create a blob to hold the data. Give it a file name\n",
    "    blob = bucket.blob(img_name+\".\"+img_type)\n",
    "    # Upload the img_data contents to the blob\n",
    "    blob.upload_from_file(img_data)\n",
    "    print(\"Picture successfully uploaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf557c4",
   "metadata": {},
   "source": [
    " # Predicted vs Actual\n",
    " - Scatter plot of predicted vs actual\n",
    " - Shows how accurate the model is (closer to the line means better prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of predicted vs. actual\n",
    "\n",
    "# Define what name the image file for this picture will have and the type of image it will be saved as\n",
    "img_name = \"actual_vs_predicted\"\n",
    "img_type = \"png\"\n",
    "\n",
    "df = sdf.select(\"prediction\",\"totalFare\").sample(False, 0.01, seed=SEED).toPandas()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(x=df['totalFare'], y=df['prediction'], alpha=0.2)\n",
    "plt.plot([df['totalFare'].min(), df['totalFare'].max()],\n",
    "         [df['totalFare'].min(), df['totalFare'].max()],\n",
    "         color='red', linestyle='--', label='Ideal Fit')  # Add a reference line for ideal fit\n",
    "plt.title('Predicted vs Actual')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.xticks([0,100,200,300,400,500,600,700,800])  # Tick marks from 0 to 1000 with step of 100\n",
    "plt.yticks([0,100,200,300,400,500,600,700,800,900,1000])  # Same for y-axis\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "save_fig(plt,img_name,img_type)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e41c1b",
   "metadata": {},
   "source": [
    " # Histogram of Residuals\n",
    " - Normality: If the residuals are normally distributed (bell-shaped curve), this supports the normality assumption of linear regression. If the residuals are skewed or have outliers, this suggests violations of the normality assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb6c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define what name the image file for this picture will have and the type of image it will be saved as\n",
    "img_name = \"histogram_of_residuals\"\n",
    "img_type = \"png\"\n",
    "\n",
    "# Extract actual values and predicted values\n",
    "result_df = sdf.select(\"prediction\",\"totalFare\").sample(False, 0.01, seed=SEED).toPandas()\n",
    "\n",
    "# Compute residuals (difference between actual and predicted)\n",
    "result_df['residual'] = result_df['totalFare'] - result_df['prediction']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(result_df['residual'], kde=True, bins=30, color='blue')\n",
    "\n",
    "plt.title('Residuals Histogram')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "save_fig(plt,img_name,img_type)\n",
    "plt.show()\n",
    "\n",
    "del result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6296aa",
   "metadata": {},
   "source": [
    " # Correlation Matrix\n",
    " - With many new features created and most numerical, we can check correlations for more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a322c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "\n",
    "# 1st, gett all numerical columns to do the correlation matrix\n",
    "\n",
    "# Step 1: Grab one row from the PySpark DataFrame and convert it to Pandas\n",
    "row_df = sdf.limit(1).toPandas()\n",
    "# Step 2: Extract numerical columns from the Pandas DataFrame\n",
    "numeric_columns = row_df.select_dtypes(include=['number']).columns.tolist()\n",
    "# Step 3: Re-select the numerical columns from the original PySpark DataFrame\n",
    "sdf_numeric = sdf.select(*numeric_columns).drop(\"isRefundableBinarized\",\"baseFare\")\n",
    "# Step 4: Convert the selected PySpark DataFrame to a Pandas DataFrame\n",
    "df = sdf_numeric.sample(False, 0.01, seed=SEED).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85329a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd, Compute correlation matrix\n",
    "\n",
    "# Define what name the image file for this picture will have and the type of image it will be saved as\n",
    "img_name = \"correlation_matrix_post_pipeline\"\n",
    "img_type = \"png\"\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Create a mask to remove the upper triangle of the correlation matrix\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Apply the mask to the correlation matrix (set upper triangle to NaN or zero)\n",
    "masked_corr_matrix = corr_matrix.mask(mask)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(masked_corr_matrix, annot=False, cmap='coolwarm', fmt=\".2f\", linewidths=1)\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "save_fig(plt,img_name,img_type)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a44f3",
   "metadata": {},
   "source": [
    " # Feature Coefficients\n",
    " - Plots the coefficients of each feature\n",
    " - Note: If changing anything related to the ordering of features in model creation,\n",
    "   then the features here must also be changed to reflect the same order. Otherwise, the coefficients will not actually correlate to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients and intercept\n",
    "coefficients = lr_model.coefficients\n",
    "\n",
    "# Get the feature names (order must match the feature vector in assembler)\n",
    "feature_columns = [\n",
    "    \"startingAirportVector\", \"destinationAirportVector\", \"fareBasisCodeVector\",\n",
    "    \"segmentsArrivalAirportCodeVector\", \"segmentsDepartureAirportCodeVector\",\n",
    "    \"segmentsAirlineNameVector\", \"segmentsAirlineCodeVector\", \"segmentsEquipmentDescriptionVector\",\n",
    "    \"segmentsDistanceVector\", \"segmentsCabinCodeVector\", \"numScaled\", \n",
    "    \"searchDateisWeekend\", \"flightDateisWeekend\",\n",
    "    \"isBasicEconomyBinarized\", \"isRefundableBinarized\", \"isNonStopBinarized\"\n",
    "]\n",
    "\n",
    "# Combine coefficients with feature names\n",
    "feature_coefficients = list(zip(feature_columns, coefficients))\n",
    "\n",
    "# Optionally, use pandas to display the coefficients for easier interpretation\n",
    "feature_coefficients_df = pd.DataFrame(feature_coefficients, columns=[\"Feature\", \"Coefficient\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(feature_coefficients_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45008da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what name the image file for this picture will have and the type of image it will be saved as\n",
    "img_name = \"feature_coefficients\"\n",
    "img_type = \"png\"\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=feature_coefficients_df)\n",
    "plt.title('Feature Coefficients from Linear Regression')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "save_fig(plt,img_name,img_type)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86377d4f",
   "metadata": {},
   "source": [
    "# Get model Hyperparameters\n",
    "- These are the parameters of the best model produced from ModelCreation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print hyperparameters from Linear Regression Model\n",
    "print(\"Best Model Parameters:\")\n",
    "for param, value in lr_model.extractParamMap().items():\n",
    "    print(f\"{param.name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675cd68e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
